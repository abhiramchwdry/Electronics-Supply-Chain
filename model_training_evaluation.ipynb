{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "\n",
    "\n",
    "## 1. Import Libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up visualizations\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('scripts'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_path = os.path.abspath('scripts')\n",
    "sys.path.append(scripts_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_path(module_name, module_path):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhi\\electronics_supply_chain\\notebooks\\scripts\n"
     ]
    }
   ],
   "source": [
    "print(scripts_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhi\\electronics_supply_chain\\notebooks\\scripts\\data_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(scripts_path, \"data_preprocessing.py\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import data_preprocessing\n",
    "importlib.reload(data_preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_preprocessing module loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"data_preprocessing module loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_preprocessing' from 'C:\\\\Users\\\\nikhi\\\\electronics_supply_chain\\\\scripts\\\\data_preprocessing.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data_preprocessing\n",
    "\n",
    "importlib.reload(data_preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'pd', 'preprocess_data']\n"
     ]
    }
   ],
   "source": [
    "import data_preprocessing\n",
    "\n",
    "print(dir(data_preprocessing))  # Should include 'preprocess_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "         date  product_id  product_name product_category  supplier_id  \\\n",
      "0  2023-10-09         107             0      electronics            5   \n",
      "1  2023-08-17          21             1      electronics           10   \n",
      "2  2023-04-15         122             2      electronics           10   \n",
      "3  2023-03-31         117             3      electronics            2   \n",
      "4  2024-03-08         104             4      electronics            9   \n",
      "\n",
      "   supplier_name  supplier_location  supplier_reliability  quantity_ordered  \\\n",
      "0              0                  0                  0.90               430   \n",
      "1              1                  1                  0.77                63   \n",
      "2              2                  0                  0.90               280   \n",
      "3              3                  1                  0.94              1816   \n",
      "4              1                  2                  0.90              1218   \n",
      "\n",
      "   demand_forecast  days_to_availability  \n",
      "0              891                   151  \n",
      "1              711                    95  \n",
      "2              908                     5  \n",
      "3             1951                    40  \n",
      "4              287                   453  \n",
      "Target:\n",
      "0     315\n",
      "1    1137\n",
      "2    1007\n",
      "3    1214\n",
      "4     813\n",
      "Name: quantity_available, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import data_preprocessing\n",
    "\n",
    "# Reload the module if necessary\n",
    "importlib.reload(data_preprocessing)\n",
    "\n",
    "# Access the function\n",
    "preprocess_data_func = data_preprocessing.preprocess_data\n",
    "\n",
    "# Define the path to your sample file\n",
    "sample_file_path = 'C:\\\\Users\\\\nikhi\\\\electronics_supply_chain\\\\data\\\\electronics_supply_chain_data_500.csv'\n",
    "\n",
    "# Test the function\n",
    "try:\n",
    "    X, y = preprocess_data_func(sample_file_path)\n",
    "    print(\"Features:\")\n",
    "    print(X.head())  # Display the first few rows of the feature DataFrame\n",
    "    print(\"Target:\")\n",
    "    print(y.head())  # Display the first few rows of the target Series\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                     object\n",
      "product_id                int64\n",
      "product_name              int64\n",
      "product_category         object\n",
      "supplier_id               int64\n",
      "supplier_name             int64\n",
      "supplier_location         int64\n",
      "supplier_reliability    float64\n",
      "quantity_ordered          int64\n",
      "demand_forecast           int64\n",
      "days_to_availability      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert date columns to numeric features\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    # Drop the original date column\n",
    "    df = df.drop('date', axis=1)\n",
    "    \n",
    "    # Convert categorical columns\n",
    "    df['product_name'] = pd.factorize(df['product_name'])[0]\n",
    "    df['supplier_name'] = pd.factorize(df['supplier_name'])[0]\n",
    "    df['supplier_location'] = pd.factorize(df['supplier_location'])[0]\n",
    "    df['product_category'] = pd.factorize(df['product_category'])[0]\n",
    "    \n",
    "    # Ensure all columns are numeric\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "    # Drop any remaining non-numeric columns\n",
    "    df = df.dropna()  # Drop rows with NaN values after conversion\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('quantity_available', axis=1)\n",
    "    y = df['quantity_available']\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using the preprocess_data function\n",
    "X, y = preprocess_data('C:\\\\Users\\\\nikhi\\\\electronics_supply_chain\\\\data\\\\electronics_supply_chain_data_500.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.head())  # Debugging line to check the initial DataFrame\n",
    "    \n",
    "    # Convert date columns to numeric features\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    # Drop the original date column\n",
    "    df = df.drop('date', axis=1)\n",
    "    \n",
    "    # Convert categorical columns\n",
    "    df['product_name'] = pd.factorize(df['product_name'])[0]\n",
    "    df['supplier_name'] = pd.factorize(df['supplier_name'])[0]\n",
    "    df['supplier_location'] = pd.factorize(df['supplier_location'])[0]\n",
    "    df['product_category'] = pd.factorize(df['product_category'])[0]\n",
    "    \n",
    "    # Ensure all columns are numeric\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "    # Drop any remaining non-numeric columns\n",
    "    df = df.dropna()  # Drop rows with NaN values after conversion\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('quantity_available', axis=1)\n",
    "    y = df['quantity_available']\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  product_id              product_name product_category  \\\n",
      "0  2023-10-09         107   Microsoft Surface Pro 9      electronics   \n",
      "1  2023-08-17          21        Logitech G502 Hero      electronics   \n",
      "2  2023-04-15         122  Microsoft Surface Book 3      electronics   \n",
      "3  2023-03-31         117     Epson EcoTank ET-2760      electronics   \n",
      "4  2024-03-08         104   NVIDIA GeForce RTX 3080      electronics   \n",
      "\n",
      "   order_date availability_date  supplier_id       supplier_name  \\\n",
      "0  2023-06-05        2023-11-03            5     TechSource Inc.   \n",
      "1  2023-02-07        2023-05-13           10           GadgetPro   \n",
      "2  2024-05-29        2024-06-03           10          FutureTech   \n",
      "3  2023-04-13        2023-05-23            2  PremiumElectronics   \n",
      "4  2023-04-13        2024-07-09            9           GadgetPro   \n",
      "\n",
      "  supplier_location  supplier_reliability  quantity_ordered  \\\n",
      "0             Japan                  0.90               430   \n",
      "1                UK                  0.77                63   \n",
      "2             Japan                  0.90               280   \n",
      "3                UK                  0.94              1816   \n",
      "4            Brazil                  0.90              1218   \n",
      "\n",
      "   quantity_available  demand_forecast  \n",
      "0                 315              891  \n",
      "1                1137              711  \n",
      "2                1007              908  \n",
      "3                1214             1951  \n",
      "4                 813              287  \n",
      "Features shape: (0, 14)\n",
      "Target shape: (0,)\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_data(file_path)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Original Data Shape:\", df.shape)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna()\n",
    "    print(\"Data Shape After Dropna:\", df.shape)\n",
    "    \n",
    "    # Convert categorical variables to numeric\n",
    "    df['product_name'] = pd.factorize(df['product_name'])[0]\n",
    "    df['supplier_name'] = pd.factorize(df['supplier_name'])[0]\n",
    "    df['supplier_location'] = pd.factorize(df['supplier_location'])[0]\n",
    "    \n",
    "    # Convert date columns\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "    df['availability_date'] = pd.to_datetime(df['availability_date'])\n",
    "    df['days_to_availability'] = (df['availability_date'] - df['order_date']).dt.days\n",
    "    \n",
    "    # Drop original date columns\n",
    "    df = df.drop(['order_date', 'availability_date'], axis=1)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('quantity_available', axis=1)\n",
    "    y = df['quantity_available']\n",
    "    \n",
    "    print(\"Features Shape:\", X.shape)\n",
    "    print(\"Target Shape:\", y.shape)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'electronics_supply_chain_data_500.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:\\\\Users\\\\nikhi\\\\electronics_supply_chain\\\\data\\\\electronics_supply_chain_data_500.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (257, 13)\n",
      "         date  product_id              product_name product_category  \\\n",
      "0  2023-10-09         107   Microsoft Surface Pro 9      electronics   \n",
      "1  2023-08-17          21        Logitech G502 Hero      electronics   \n",
      "2  2023-04-15         122  Microsoft Surface Book 3      electronics   \n",
      "3  2023-03-31         117     Epson EcoTank ET-2760      electronics   \n",
      "4  2024-03-08         104   NVIDIA GeForce RTX 3080      electronics   \n",
      "\n",
      "   order_date availability_date  supplier_id       supplier_name  \\\n",
      "0  2023-06-05        2023-11-03            5     TechSource Inc.   \n",
      "1  2023-02-07        2023-05-13           10           GadgetPro   \n",
      "2  2024-05-29        2024-06-03           10          FutureTech   \n",
      "3  2023-04-13        2023-05-23            2  PremiumElectronics   \n",
      "4  2023-04-13        2024-07-09            9           GadgetPro   \n",
      "\n",
      "  supplier_location  supplier_reliability  quantity_ordered  \\\n",
      "0             Japan                  0.90               430   \n",
      "1                UK                  0.77                63   \n",
      "2             Japan                  0.90               280   \n",
      "3                UK                  0.94              1816   \n",
      "4            Brazil                  0.90              1218   \n",
      "\n",
      "   quantity_available  demand_forecast  \n",
      "0                 315              891  \n",
      "1                1137              711  \n",
      "2                1007              908  \n",
      "3                1214             1951  \n",
      "4                 813              287  \n",
      "Data Shape After Dropna: (257, 13)\n",
      "         date  product_id              product_name product_category  \\\n",
      "0  2023-10-09         107   Microsoft Surface Pro 9      electronics   \n",
      "1  2023-08-17          21        Logitech G502 Hero      electronics   \n",
      "2  2023-04-15         122  Microsoft Surface Book 3      electronics   \n",
      "3  2023-03-31         117     Epson EcoTank ET-2760      electronics   \n",
      "4  2024-03-08         104   NVIDIA GeForce RTX 3080      electronics   \n",
      "\n",
      "   order_date availability_date  supplier_id       supplier_name  \\\n",
      "0  2023-06-05        2023-11-03            5     TechSource Inc.   \n",
      "1  2023-02-07        2023-05-13           10           GadgetPro   \n",
      "2  2024-05-29        2024-06-03           10          FutureTech   \n",
      "3  2023-04-13        2023-05-23            2  PremiumElectronics   \n",
      "4  2023-04-13        2024-07-09            9           GadgetPro   \n",
      "\n",
      "  supplier_location  supplier_reliability  quantity_ordered  \\\n",
      "0             Japan                  0.90               430   \n",
      "1                UK                  0.77                63   \n",
      "2             Japan                  0.90               280   \n",
      "3                UK                  0.94              1816   \n",
      "4            Brazil                  0.90              1218   \n",
      "\n",
      "   quantity_available  demand_forecast  \n",
      "0                 315              891  \n",
      "1                1137              711  \n",
      "2                1007              908  \n",
      "3                1214             1951  \n",
      "4                 813              287  \n",
      "Data After Processing Date Columns:\n",
      "         date  product_id  product_name product_category  supplier_id  \\\n",
      "0  2023-10-09         107             0      electronics            5   \n",
      "1  2023-08-17          21             1      electronics           10   \n",
      "2  2023-04-15         122             2      electronics           10   \n",
      "3  2023-03-31         117             3      electronics            2   \n",
      "4  2024-03-08         104             4      electronics            9   \n",
      "\n",
      "   supplier_name  supplier_location  supplier_reliability  quantity_ordered  \\\n",
      "0              0                  0                  0.90               430   \n",
      "1              1                  1                  0.77                63   \n",
      "2              2                  0                  0.90               280   \n",
      "3              3                  1                  0.94              1816   \n",
      "4              1                  2                  0.90              1218   \n",
      "\n",
      "   quantity_available  demand_forecast  days_to_availability  \n",
      "0                 315              891                   151  \n",
      "1                1137              711                    95  \n",
      "2                1007              908                     5  \n",
      "3                1214             1951                    40  \n",
      "4                 813              287                   453  \n",
      "date                     object\n",
      "product_id                int64\n",
      "product_name              int64\n",
      "product_category         object\n",
      "supplier_id               int64\n",
      "supplier_name             int64\n",
      "supplier_location         int64\n",
      "supplier_reliability    float64\n",
      "quantity_ordered          int64\n",
      "quantity_available        int64\n",
      "demand_forecast           int64\n",
      "days_to_availability      int64\n",
      "dtype: object\n",
      "date                    0\n",
      "product_id              0\n",
      "product_name            0\n",
      "product_category        0\n",
      "supplier_id             0\n",
      "supplier_name           0\n",
      "supplier_location       0\n",
      "supplier_reliability    0\n",
      "quantity_ordered        0\n",
      "quantity_available      0\n",
      "demand_forecast         0\n",
      "days_to_availability    0\n",
      "dtype: int64\n",
      "Features Shape: (257, 11)\n",
      "Target Shape: (257,)\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_data(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (257, 13)\n",
      "         date  product_id              product_name product_category  \\\n",
      "0  2023-10-09         107   Microsoft Surface Pro 9      electronics   \n",
      "1  2023-08-17          21        Logitech G502 Hero      electronics   \n",
      "2  2023-04-15         122  Microsoft Surface Book 3      electronics   \n",
      "3  2023-03-31         117     Epson EcoTank ET-2760      electronics   \n",
      "4  2024-03-08         104   NVIDIA GeForce RTX 3080      electronics   \n",
      "\n",
      "   order_date availability_date  supplier_id       supplier_name  \\\n",
      "0  2023-06-05        2023-11-03            5     TechSource Inc.   \n",
      "1  2023-02-07        2023-05-13           10           GadgetPro   \n",
      "2  2024-05-29        2024-06-03           10          FutureTech   \n",
      "3  2023-04-13        2023-05-23            2  PremiumElectronics   \n",
      "4  2023-04-13        2024-07-09            9           GadgetPro   \n",
      "\n",
      "  supplier_location  supplier_reliability  quantity_ordered  \\\n",
      "0             Japan                  0.90               430   \n",
      "1                UK                  0.77                63   \n",
      "2             Japan                  0.90               280   \n",
      "3                UK                  0.94              1816   \n",
      "4            Brazil                  0.90              1218   \n",
      "\n",
      "   quantity_available  demand_forecast  \n",
      "0                 315              891  \n",
      "1                1137              711  \n",
      "2                1007              908  \n",
      "3                1214             1951  \n",
      "4                 813              287  \n",
      "Data Shape After Dropna: (257, 13)\n",
      "Features Shape: (257, 11)\n",
      "Target Shape: (257,)\n",
      "Model R^2 Score: -0.11522288339094655\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# File path\n",
    "file_path = 'C:\\\\Users\\\\nikhi\\\\electronics_supply_chain\\\\data\\\\electronics_supply_chain_data_500.csv'\n",
    "\n",
    "# Load and preprocess the data\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Print original shape and first few rows\n",
    "    print(\"Original Data Shape:\", df.shape)\n",
    "    print(df.head())\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna()\n",
    "    print(\"Data Shape After Dropna:\", df.shape)\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "    df['availability_date'] = pd.to_datetime(df['availability_date'])\n",
    "    \n",
    "    # Feature engineering: create new features from dates\n",
    "    df['days_to_availability'] = (df['availability_date'] - df['order_date']).dt.days\n",
    "    df['days_since_date'] = (df['date'] - df['order_date']).dt.days\n",
    "    \n",
    "    # Drop original date columns\n",
    "    df = df.drop(columns=['date', 'order_date', 'availability_date'])\n",
    "    \n",
    "    # Convert categorical features to numeric\n",
    "    df['product_name'] = df['product_name'].astype('category').cat.codes\n",
    "    df['product_category'] = df['product_category'].astype('category').cat.codes\n",
    "    df['supplier_name'] = df['supplier_name'].astype('category').cat.codes\n",
    "    df['supplier_location'] = df['supplier_location'].astype('category').cat.codes\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preprocess_data(file_path)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['days_to_availability'])\n",
    "y = df['days_to_availability']\n",
    "\n",
    "# Print shapes\n",
    "print(\"Features Shape:\", X.shape)\n",
    "print(\"Target Shape:\", y.shape)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Model R^2 Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 136.43115384615388\n",
      "Mean Squared Error: 28469.681561538462\n",
      "R^2 Score: -0.11522288339094655\n",
      "Feature Importances:\n",
      "                 Feature  Importance\n",
      "10       days_since_date    0.228860\n",
      "9        demand_forecast    0.125729\n",
      "8     quantity_available    0.108571\n",
      "7       quantity_ordered    0.101153\n",
      "1           product_name    0.092396\n",
      "4          supplier_name    0.081824\n",
      "0             product_id    0.081075\n",
      "6   supplier_reliability    0.080276\n",
      "3            supplier_id    0.060495\n",
      "5      supplier_location    0.039620\n",
      "2       product_category    0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "# Feature Importance\n",
    "feature_importances = model.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score: -0.1016873784959564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Load model\n",
    "model = joblib.load('random_forest_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nikhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\nikhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nikhi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nikhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\nikhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (1.14.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\nikhi\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: six in c:\\users\\nikhi\\appdata\\roaming\\python\\python312\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.2-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.8 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.0/9.8 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.6/9.8 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.8 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['date', 'product_id', 'product_name', 'product_category', 'order_date',\n",
      "       'availability_date', 'supplier_id', 'supplier_name',\n",
      "       'supplier_location', 'supplier_reliability', 'quantity_ordered',\n",
      "       'quantity_available', 'demand_forecast'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load historical order data\n",
    "df = pd.read_csv('C:/Users/nikhi/electronics_supply_chain/data/electronics_supply_chain_data_500.csv')\n",
    "\n",
    "# Print the column names\n",
    "print(\"Columns in DataFrame:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def feature_engineering(X_train, X_test):\n",
    "    # Identify non-numeric columns\n",
    "    non_numeric_cols = X_train.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Convert non-numeric columns to numeric using one-hot encoding\n",
    "    X_train = pd.get_dummies(X_train, columns=non_numeric_cols, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=non_numeric_cols, drop_first=True)\n",
    "    \n",
    "    # Align columns between train and test datasets\n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "    \n",
    "    # Check if all features are numeric\n",
    "    if not X_train.applymap(pd.api.types.is_numeric_dtype).all().all():\n",
    "        raise ValueError(\"Feature engineering expects all features to be numeric.\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_models():\n",
    "    # Load and preprocess data\n",
    "    X, y = preprocess_data('C:/Users/nikhi/electronics_supply_chain/data/electronics_supply_chain_data_500.csv')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature engineering\n",
    "    X_train_scaled, X_test_scaled = feature_engineering(X_train, X_test)\n",
    "    \n",
    "    # Hyperparameter tuning for Random Forest\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "    grid_search_rf.fit(X_train_scaled, y_train)\n",
    "    best_rf_model = grid_search_rf.best_estimator_\n",
    "    \n",
    "    # Train other models\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Fit models\n",
    "    best_rf_model.fit(X_train_scaled, y_train)\n",
    "    xgb_model.fit(X_train_scaled, y_train)\n",
    "    lgb_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Save models\n",
    "    joblib.dump(best_rf_model, 'C:/Users/nikhi/electronics_supply_chain/models/random_forest_model.pkl')\n",
    "    joblib.dump(xgb_model, 'C:/Users/nikhi/electronics_supply_chain/models/xgboost_model.pkl')\n",
    "    joblib.dump(lgb_model, 'C:/Users/nikhi/electronics_supply_chain/models/lightgbm_model.pkl')\n",
    "    \n",
    "    # Evaluate models\n",
    "    rf_preds = best_rf_model.predict(X_test_scaled)\n",
    "    xgb_preds = xgb_model.predict(X_test_scaled)\n",
    "    lgb_preds = lgb_model.predict(X_test_scaled)\n",
    "    \n",
    "    rf_rmse = mean_squared_error(y_test, rf_preds, squared=False)\n",
    "    xgb_rmse = mean_squared_error(y_test, xgb_preds, squared=False)\n",
    "    lgb_rmse = mean_squared_error(y_test, lgb_preds, squared=False)\n",
    "    \n",
    "    rf_r2 = r2_score(y_test, rf_preds)\n",
    "    xgb_r2 = r2_score(y_test, xgb_preds)\n",
    "    lgb_r2 = r2_score(y_test, lgb_preds)\n",
    "    \n",
    "    print(f\"Random Forest RMSE: {rf_rmse}\")\n",
    "    print(f\"XGBoost RMSE: {xgb_rmse}\")\n",
    "    print(f\"LightGBM RMSE: {lgb_rmse}\")\n",
    "    \n",
    "    print(f\"Random Forest R²: {rf_r2}\")\n",
    "    print(f\"XGBoost R²: {xgb_r2}\")\n",
    "    print(f\"LightGBM R²: {lgb_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m rmse_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m r2_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      8\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "mse_results = {}\n",
    "rmse_results = {}\n",
    "r2_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mse_results[name] = mse\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse_results[name] = rmse\n",
    "\n",
    "    # Calculate R2 score\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    r2_results[name] = r2\n",
    "\n",
    "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
